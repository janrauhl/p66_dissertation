{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a480f4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 12:49:29.010321: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2023-08-28 12:49:29.010338: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-08-28 12:49:29.010345: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-08-28 12:49:29.010373: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-28 12:49:29.010389: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "eff = tf.keras.models.load_model('/Volumes/Janrauhl/model_weights/effnet_wo_tl.h5')\n",
    "effb0 = tf.saved_model.load('/Volumes/Janrauhl/model_weights/effnet_b0_tl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62076392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = tf.keras.models.load_model('/Volumes/Janrauhl/model_weights/res_tl.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7ea655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26880 files belonging to 6 classes.\n",
      "Found 7178 files belonging to 7 classes.\n",
      "['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise']\n",
      "6\n",
      "Shape of a sample image in training_ds_resized: (32, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 12:49:39.388217: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate, Dense, GlobalAveragePooling2D \n",
    "from tensorflow.keras.models import Model\n",
    "batch_size = 32\n",
    "img_height = 200 \n",
    "img_width = 200 \n",
    "training_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'DownFER/train', # directory path\n",
    "    validation_split = None, \n",
    "    subset = None, \n",
    "    image_size = (img_height, img_width), # image size of height and width\n",
    "    batch_size = 32# batch size\n",
    ")\n",
    "testing_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'DownFER/test', # directory path\n",
    "    validation_split = None, \n",
    "    subset = None, \n",
    "    image_size = (img_height, img_width), # image size of height and width\n",
    "    batch_size = 32 # batch size\n",
    ")\n",
    "class_names = training_ds.class_names\n",
    "print(class_names)\n",
    "print(len(class_names))\n",
    "# configuring dataset for performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# cache() keeps images in memory to ensure dataset does not become a bottleneck \n",
    "  # while training the model\n",
    "# prefetch() overlaps data preprocessing and model execution while training\n",
    "num_classes = len(class_names)\n",
    "training_ds = training_ds.cache().prefetch(buffer_size = AUTOTUNE) # for training\n",
    "testing_ds = testing_ds.cache().prefetch(buffer_size = AUTOTUNE) # for testing\n",
    "# One-hot encode the labels\n",
    "def one_hot_encode(image, label):\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    return image, label\n",
    "\n",
    "# Apply one-hot encoding to the dataset\n",
    "training_ds = training_ds.map(one_hot_encode)\n",
    "testing_ds = testing_ds.map(one_hot_encode)\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input \n",
    "target_size =  (224,224) \n",
    "\n",
    "def preprocess_image(image,label): \n",
    "    image = tf.image.resize(image, target_size) \n",
    "    image = preprocess_input(image) \n",
    "    return image, label \n",
    "training_ds_resized = training_ds.map(preprocess_image) \n",
    "testing_ds_resized = testing_ds.map(preprocess_image) \n",
    "sample_image, _ = next(iter(testing_ds_resized.take(1)))\n",
    "sample_image_shape = sample_image.shape\n",
    "\n",
    "print(\"Shape of a sample image in training_ds_resized:\", sample_image_shape)\n",
    "\n",
    "def plot_model(model_saved, N, path = None): \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N), model_saved.history['loss'], \n",
    "             label = 'training loss') # training loss\n",
    "    plt.plot(np.arange(0, N), model_saved.history['val_loss'], \n",
    "             label = 'test loss') # testing loss\n",
    "    plt.plot(np.arange(0, N), model_saved.history['accuracy'], \n",
    "             label = 'training accuracy') # training accuracy\n",
    "    plt.plot(np.arange(0, N), model_saved.history['val_accuracy'], \n",
    "             label = 'test accuracy') # testing accuracy\n",
    "    plt.title(\"Training and Testing Loss and Accuracy\") # title of comparative line graph\n",
    "    plt.xlabel(\"Epoch #\") # x axis label\n",
    "    plt.ylabel(\"Loss/Accuracy\") # y axis label\n",
    "    plt.legend(loc = \"upper right\") # legend\n",
    "\n",
    "    if path: \n",
    "        plt.savefig(path) \n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19b6464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 12:49:41.511254: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - ETA: 0s - loss: 1.8101 - accuracy: 0.1678"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 12:50:19.642404: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 50s 57ms/step - loss: 1.8101 - accuracy: 0.1678 - val_loss: 1.6639 - val_accuracy: 0.0155\n",
      "Epoch 2/20\n",
      "840/840 [==============================] - 49s 58ms/step - loss: 1.7985 - accuracy: 0.1824 - val_loss: 1.6275 - val_accuracy: 0.1220\n",
      "Epoch 3/20\n",
      "840/840 [==============================] - 50s 59ms/step - loss: 1.7611 - accuracy: 0.2173 - val_loss: 1.6322 - val_accuracy: 0.1357\n",
      "Epoch 4/20\n",
      "840/840 [==============================] - 51s 61ms/step - loss: 1.7340 - accuracy: 0.2416 - val_loss: 1.6151 - val_accuracy: 0.1594\n",
      "Epoch 5/20\n",
      "840/840 [==============================] - 52s 61ms/step - loss: 1.7167 - accuracy: 0.2540 - val_loss: 1.5977 - val_accuracy: 0.1694\n",
      "Epoch 6/20\n",
      "840/840 [==============================] - 50s 60ms/step - loss: 1.7020 - accuracy: 0.2645 - val_loss: 1.5978 - val_accuracy: 0.1690\n",
      "Epoch 7/20\n",
      "840/840 [==============================] - 49s 59ms/step - loss: 1.6878 - accuracy: 0.2715 - val_loss: 1.5976 - val_accuracy: 0.1659\n",
      "Epoch 8/20\n",
      "840/840 [==============================] - 49s 58ms/step - loss: 1.6751 - accuracy: 0.2766 - val_loss: 1.5961 - val_accuracy: 0.1677\n",
      "Epoch 9/20\n",
      "840/840 [==============================] - 48s 57ms/step - loss: 1.6639 - accuracy: 0.2823 - val_loss: 1.5928 - val_accuracy: 0.1645\n",
      "Epoch 10/20\n",
      "840/840 [==============================] - 48s 57ms/step - loss: 1.6534 - accuracy: 0.2857 - val_loss: 1.5897 - val_accuracy: 0.1654\n",
      "Epoch 11/20\n",
      "840/840 [==============================] - 48s 57ms/step - loss: 1.6453 - accuracy: 0.2864 - val_loss: 1.5852 - val_accuracy: 0.1700\n",
      "Epoch 12/20\n",
      "840/840 [==============================] - 48s 57ms/step - loss: 1.6373 - accuracy: 0.2898 - val_loss: 1.5728 - val_accuracy: 0.1773\n",
      "Epoch 13/20\n",
      "840/840 [==============================] - 48s 57ms/step - loss: 1.6314 - accuracy: 0.2920 - val_loss: 1.5705 - val_accuracy: 0.1740\n",
      "Epoch 14/20\n",
      "840/840 [==============================] - 48s 57ms/step - loss: 1.6267 - accuracy: 0.2926 - val_loss: 1.5667 - val_accuracy: 0.1808\n",
      "Epoch 15/20\n",
      "840/840 [==============================] - 48s 57ms/step - loss: 1.6220 - accuracy: 0.2936 - val_loss: 1.5527 - val_accuracy: 0.1884\n",
      "Epoch 16/20\n",
      "840/840 [==============================] - 48s 57ms/step - loss: 1.6188 - accuracy: 0.2957 - val_loss: 1.5496 - val_accuracy: 0.1938\n",
      "Epoch 17/20\n",
      "840/840 [==============================] - 48s 57ms/step - loss: 1.6159 - accuracy: 0.2968 - val_loss: 1.5427 - val_accuracy: 0.1971\n",
      "Epoch 18/20\n",
      "840/840 [==============================] - 48s 57ms/step - loss: 1.6127 - accuracy: 0.2969 - val_loss: 1.5465 - val_accuracy: 0.1952\n",
      "Epoch 19/20\n",
      "840/840 [==============================] - 48s 57ms/step - loss: 1.6104 - accuracy: 0.2985 - val_loss: 1.5408 - val_accuracy: 0.2044\n",
      "Epoch 20/20\n",
      "840/840 [==============================] - 48s 57ms/step - loss: 1.6090 - accuracy: 0.2968 - val_loss: 1.5410 - val_accuracy: 0.2098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2f763ac20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras import layers\n",
    "# batch_size = 32\n",
    "# img_height = 224\n",
    "# img_width = 224 \n",
    "\n",
    "# inputs = layers.Input(shape=(img_width,img_height,3), batch_size = batch_size) \n",
    "\n",
    "# #using model without transfer learnaing\n",
    "# outputs = EfficientNetB0(include_top = True, weights = None, classes = num_classes)(inputs) \n",
    "# eff_wo_tl = tf.keras.Model(inputs,outputs) \n",
    "# eff_wo_tl.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "# eff_wo_tl.summary() \n",
    "# eff_wo_tl.fit(training_ds_resized, validation_data = testing_ds_resized, batch_size = batch_size, epochs = 20) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#efficient net b0 with transfer learning from image net\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224 \n",
    "\n",
    "inputs = layers.Input(shape=(img_height, img_width, 3))\n",
    "x = inputs\n",
    "eff_b0_tl = EfficientNetB0(include_top=False, input_tensor=x, weights=None)\n",
    "\n",
    "# Freeze the pretrained weights\n",
    "eff_b0_tl.trainable = False\n",
    "\n",
    "# Rebuild top\n",
    "x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(eff_b0_tl.output)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "top_dropout_rate = 0.2\n",
    "x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "# Compile\n",
    "eff_b0_tl = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "eff_b0_tl.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "eff_b0_tl.fit(training_ds_resized, validation_data = testing_ds_resized, batch_size = batch_size, epochs = 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80bb1406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 13:05:56.963368: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - ETA: 0s - loss: 21.4045 - accuracy: 0.3023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 13:06:48.581465: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 56s 66ms/step - loss: 21.4045 - accuracy: 0.3023 - val_loss: 24.1477 - val_accuracy: 0.0571\n",
      "Epoch 2/20\n",
      "840/840 [==============================] - 56s 67ms/step - loss: 10.4773 - accuracy: 0.3555 - val_loss: 13.1755 - val_accuracy: 0.2285\n",
      "Epoch 3/20\n",
      "840/840 [==============================] - 56s 66ms/step - loss: 10.2265 - accuracy: 0.3404 - val_loss: 23.1162 - val_accuracy: 0.1559\n",
      "Epoch 4/20\n",
      "840/840 [==============================] - 56s 66ms/step - loss: 11.2041 - accuracy: 0.3527 - val_loss: 9.3247 - val_accuracy: 0.2317\n",
      "Epoch 5/20\n",
      "840/840 [==============================] - 278s 332ms/step - loss: 10.8778 - accuracy: 0.3562 - val_loss: 11.1868 - val_accuracy: 0.2044\n",
      "Epoch 6/20\n",
      "840/840 [==============================] - 55s 66ms/step - loss: 9.7427 - accuracy: 0.3747 - val_loss: 13.2995 - val_accuracy: 0.1686\n",
      "Epoch 7/20\n",
      "840/840 [==============================] - 55s 65ms/step - loss: 10.2722 - accuracy: 0.3744 - val_loss: 17.0608 - val_accuracy: 0.1661\n",
      "Epoch 8/20\n",
      "840/840 [==============================] - 55s 66ms/step - loss: 10.0811 - accuracy: 0.3865 - val_loss: 12.7000 - val_accuracy: 0.1829\n",
      "Epoch 9/20\n",
      "840/840 [==============================] - 55s 65ms/step - loss: 11.7661 - accuracy: 0.3854 - val_loss: 27.5000 - val_accuracy: 0.2083\n",
      "Epoch 10/20\n",
      "840/840 [==============================] - 58s 69ms/step - loss: 13.6795 - accuracy: 0.3755 - val_loss: 17.7497 - val_accuracy: 0.1432\n",
      "Epoch 11/20\n",
      "840/840 [==============================] - 59s 71ms/step - loss: 15.0157 - accuracy: 0.3769 - val_loss: 22.3421 - val_accuracy: 0.0946\n",
      "Epoch 12/20\n",
      "840/840 [==============================] - 58s 68ms/step - loss: 16.3853 - accuracy: 0.3741 - val_loss: 31.7811 - val_accuracy: 0.2060\n",
      "Epoch 13/20\n",
      "840/840 [==============================] - 57s 68ms/step - loss: 15.9167 - accuracy: 0.3897 - val_loss: 19.8827 - val_accuracy: 0.1652\n",
      "Epoch 14/20\n",
      "840/840 [==============================] - 56s 67ms/step - loss: 17.9398 - accuracy: 0.3867 - val_loss: 29.9719 - val_accuracy: 0.1193\n",
      "Epoch 15/20\n",
      "840/840 [==============================] - 57s 68ms/step - loss: 19.1509 - accuracy: 0.3877 - val_loss: 20.4755 - val_accuracy: 0.2310\n",
      "Epoch 16/20\n",
      "840/840 [==============================] - 118s 140ms/step - loss: 20.4430 - accuracy: 0.3921 - val_loss: 25.4178 - val_accuracy: 0.1673\n",
      "Epoch 17/20\n",
      "840/840 [==============================] - 348s 415ms/step - loss: 22.6214 - accuracy: 0.3915 - val_loss: 32.6800 - val_accuracy: 0.1676\n",
      "Epoch 18/20\n",
      "840/840 [==============================] - 493s 587ms/step - loss: 27.3559 - accuracy: 0.3907 - val_loss: 40.2283 - val_accuracy: 0.1356\n",
      "Epoch 19/20\n",
      "840/840 [==============================] - 494s 588ms/step - loss: 29.0990 - accuracy: 0.3974 - val_loss: 29.3214 - val_accuracy: 0.1879\n",
      "Epoch 20/20\n",
      "840/840 [==============================] - 24097s 29s/step - loss: 28.1447 - accuracy: 0.4023 - val_loss: 30.5982 - val_accuracy: 0.2580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x31cbc7160>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(image_height, image_width, 3)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_ds_resized, validation_data = testing_ds_resized, batch_size = batch_size, epochs = 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb18f6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(32, 224, 224, 3)]       0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional  (None, 6)                 4057257   \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4057257 (15.48 MB)\n",
      "Trainable params: 4015234 (15.32 MB)\n",
      "Non-trainable params: 42023 (164.16 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 21:19:24.793906: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - ETA: 0s - loss: 1.7350 - accuracy: 0.3353"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 21:21:59.615143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 169s 192ms/step - loss: 1.7350 - accuracy: 0.3353 - val_loss: 1.5270 - val_accuracy: 0.2527\n",
      "Epoch 2/20\n",
      "840/840 [==============================] - 162s 192ms/step - loss: 1.2824 - accuracy: 0.4863 - val_loss: 1.4363 - val_accuracy: 0.3476\n",
      "Epoch 3/20\n",
      "840/840 [==============================] - 167s 198ms/step - loss: 1.0768 - accuracy: 0.5721 - val_loss: 1.4403 - val_accuracy: 0.3690\n",
      "Epoch 4/20\n",
      "840/840 [==============================] - 166s 197ms/step - loss: 0.9353 - accuracy: 0.6347 - val_loss: 1.5455 - val_accuracy: 0.3247\n",
      "Epoch 5/20\n",
      "840/840 [==============================] - 164s 194ms/step - loss: 0.8382 - accuracy: 0.6720 - val_loss: 1.7855 - val_accuracy: 0.3725\n",
      "Epoch 6/20\n",
      "840/840 [==============================] - 162s 192ms/step - loss: 0.7325 - accuracy: 0.7139 - val_loss: 1.8279 - val_accuracy: 0.3930\n",
      "Epoch 7/20\n",
      "840/840 [==============================] - 160s 189ms/step - loss: 0.6139 - accuracy: 0.7641 - val_loss: 2.2309 - val_accuracy: 0.3916\n",
      "Epoch 8/20\n",
      "840/840 [==============================] - 159s 188ms/step - loss: 0.5151 - accuracy: 0.8049 - val_loss: 2.0799 - val_accuracy: 0.3438\n",
      "Epoch 9/20\n",
      "840/840 [==============================] - 159s 188ms/step - loss: 0.4170 - accuracy: 0.8418 - val_loss: 2.7994 - val_accuracy: 0.3901\n",
      "Epoch 10/20\n",
      "840/840 [==============================] - 160s 190ms/step - loss: 0.3594 - accuracy: 0.8671 - val_loss: 2.7147 - val_accuracy: 0.3926\n",
      "Epoch 11/20\n",
      "840/840 [==============================] - 162s 190ms/step - loss: 0.3201 - accuracy: 0.8814 - val_loss: 2.4587 - val_accuracy: 0.3706\n",
      "Epoch 12/20\n",
      "840/840 [==============================] - 162s 193ms/step - loss: 0.2792 - accuracy: 0.8970 - val_loss: 2.7021 - val_accuracy: 0.3605\n",
      "Epoch 13/20\n",
      "840/840 [==============================] - 165s 195ms/step - loss: 0.2531 - accuracy: 0.9065 - val_loss: 2.8423 - val_accuracy: 0.3714\n",
      "Epoch 14/20\n",
      "840/840 [==============================] - 164s 194ms/step - loss: 0.2359 - accuracy: 0.9142 - val_loss: 3.0835 - val_accuracy: 0.2825\n",
      "Epoch 15/20\n",
      "840/840 [==============================] - 162s 191ms/step - loss: 0.2159 - accuracy: 0.9213 - val_loss: 3.1348 - val_accuracy: 0.3688\n",
      "Epoch 16/20\n",
      "840/840 [==============================] - 155s 183ms/step - loss: 0.1993 - accuracy: 0.9270 - val_loss: 3.1712 - val_accuracy: 0.3777\n",
      "Epoch 17/20\n",
      "840/840 [==============================] - 152s 180ms/step - loss: 0.1816 - accuracy: 0.9325 - val_loss: 2.9712 - val_accuracy: 0.3807\n",
      "Epoch 18/20\n",
      "840/840 [==============================] - 152s 179ms/step - loss: 0.1839 - accuracy: 0.9318 - val_loss: 2.9818 - val_accuracy: 0.3831\n",
      "Epoch 19/20\n",
      "840/840 [==============================] - 154s 182ms/step - loss: 0.1678 - accuracy: 0.9387 - val_loss: 2.8956 - val_accuracy: 0.3729\n",
      "Epoch 20/20\n",
      "840/840 [==============================] - 155s 184ms/step - loss: 0.1512 - accuracy: 0.9443 - val_loss: 3.0096 - val_accuracy: 0.3651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224 \n",
    "\n",
    "inputs = layers.Input(shape=(img_width,img_height,3), batch_size = batch_size) \n",
    "\n",
    "#using model without transfer learnaing\n",
    "outputs = EfficientNetB0(include_top = True, weights = None, classes = num_classes)(inputs) \n",
    "eff_wo_tl = tf.keras.Model(inputs,outputs) \n",
    "eff_wo_tl.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "eff_wo_tl.summary() \n",
    "eff_wo_tl.fit(training_ds_resized, validation_data = testing_ds_resized, batch_size = batch_size, epochs = 20) \n",
    "eff_wo_tl.save('model_weights/effnet_wo_tl.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58a0e53e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"global_average_pooling2d_1\" is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m eff_out \u001b[38;5;241m=\u001b[39m GlobalAveragePooling2D()(eff_out)\n\u001b[1;32m      4\u001b[0m res_out \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39moutput\n\u001b[0;32m----> 5\u001b[0m res_out \u001b[38;5;241m=\u001b[39m \u001b[43mGlobalAveragePooling2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m concatenated \u001b[38;5;241m=\u001b[39m Concatenate()([eff_out,res_out])\n\u001b[1;32m      7\u001b[0m output \u001b[38;5;241m=\u001b[39m Dense(num_classes, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)(concatenated)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/keras/src/engine/input_spec.py:235\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    233\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m shape\u001b[38;5;241m.\u001b[39mrank\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m--> 235\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    237\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m         )\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"global_average_pooling2d_1\" is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 1024)"
     ]
    }
   ],
   "source": [
    "num_classes= 6 \n",
    "eff_out = eff.layers[-2].output\n",
    "eff_out = GlobalAveragePooling2D()(eff_out)\n",
    "res_out = res.layers[-2].output\n",
    "res_out = GlobalAveragePooling2D()(res_out)\n",
    "concatenated = Concatenate()([eff_out,res_out])\n",
    "output = Dense(num_classes, activation = 'softmax')(concatenated)\n",
    "ensemble = Model(inputs = [eff.input,res.input],outputs =output)\n",
    "ensemble.compile(loss='categorical-crossentropy',optmizer='adam',metrics=['accuracy'])\n",
    "ensemble.fit(training_ds_resized, validation_data = testing_ds_resized, batch_size = 32, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e5aa327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(32, 224, 224, 3)]       0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional  (None, 6)                 4057257   \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4057257 (15.48 MB)\n",
      "Trainable params: 4015234 (15.32 MB)\n",
      "Non-trainable params: 42023 (164.16 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "eff.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f77f45a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 6150      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25692038 (98.01 MB)\n",
      "Trainable params: 25638918 (97.80 MB)\n",
      "Non-trainable params: 53120 (207.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22e0113d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model signatures: _SignatureMap({'serving_default': <ConcreteFunction signature_wrapper(*, input_7) at 0x3205279D0>})\n",
      "Loaded model functions: ['__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_add_trackable_child', '_add_variable_with_custom_getter', '_checkpoint_dependencies', '_default_save_signature', '_deferred_dependencies', '_delete_tracking', '_deserialization_dependencies', '_deserialize_from_proto', '_export_to_saved_model_graph', '_gather_saveables_for_checkpoint', '_handle_deferred_dependencies', '_lookup_dependency', '_maybe_initialize_trackable', '_name_based_attribute_restore', '_name_based_restores', '_no_dependency', '_object_identifier', '_preload_simple_restoration', '_restore_from_tensors', '_self_name_based_restores', '_self_saveable_object_factories', '_self_setattr_tracking', '_self_unconditional_checkpoint_dependencies', '_self_unconditional_deferred_dependencies', '_self_unconditional_dependency_names', '_self_update_uid', '_serialize_to_proto', '_serialize_to_tensors', '_setattr_tracking', '_tf_api_names', '_tf_api_names_v1', '_track_trackable', '_trackable_children', '_unconditional_checkpoint_dependencies', '_unconditional_dependency_names', '_update_uid', 'call_and_return_all_conditional_losses', 'graph_debug_info', 'keras_api', 'layer-0', 'layer-1', 'layer-10', 'layer-100', 'layer-101', 'layer-102', 'layer-103', 'layer-104', 'layer-105', 'layer-106', 'layer-107', 'layer-108', 'layer-109', 'layer-11', 'layer-110', 'layer-111', 'layer-112', 'layer-113', 'layer-114', 'layer-115', 'layer-116', 'layer-117', 'layer-118', 'layer-119', 'layer-12', 'layer-120', 'layer-121', 'layer-122', 'layer-123', 'layer-124', 'layer-125', 'layer-126', 'layer-127', 'layer-128', 'layer-129', 'layer-13', 'layer-130', 'layer-131', 'layer-132', 'layer-133', 'layer-134', 'layer-135', 'layer-136', 'layer-137', 'layer-138', 'layer-139', 'layer-14', 'layer-140', 'layer-141', 'layer-142', 'layer-143', 'layer-144', 'layer-145', 'layer-146', 'layer-147', 'layer-148', 'layer-149', 'layer-15', 'layer-150', 'layer-151', 'layer-152', 'layer-153', 'layer-154', 'layer-155', 'layer-156', 'layer-157', 'layer-158', 'layer-159', 'layer-16', 'layer-160', 'layer-161', 'layer-162', 'layer-163', 'layer-164', 'layer-165', 'layer-166', 'layer-167', 'layer-168', 'layer-169', 'layer-17', 'layer-170', 'layer-171', 'layer-172', 'layer-173', 'layer-174', 'layer-175', 'layer-176', 'layer-177', 'layer-178', 'layer-179', 'layer-18', 'layer-180', 'layer-181', 'layer-182', 'layer-183', 'layer-184', 'layer-185', 'layer-186', 'layer-187', 'layer-188', 'layer-189', 'layer-19', 'layer-190', 'layer-191', 'layer-192', 'layer-193', 'layer-194', 'layer-195', 'layer-196', 'layer-197', 'layer-198', 'layer-199', 'layer-2', 'layer-20', 'layer-200', 'layer-201', 'layer-202', 'layer-203', 'layer-204', 'layer-205', 'layer-206', 'layer-207', 'layer-208', 'layer-209', 'layer-21', 'layer-210', 'layer-211', 'layer-212', 'layer-213', 'layer-214', 'layer-215', 'layer-216', 'layer-217', 'layer-218', 'layer-219', 'layer-22', 'layer-220', 'layer-221', 'layer-222', 'layer-223', 'layer-224', 'layer-225', 'layer-226', 'layer-227', 'layer-228', 'layer-229', 'layer-23', 'layer-230', 'layer-231', 'layer-232', 'layer-233', 'layer-234', 'layer-235', 'layer-236', 'layer-237', 'layer-238', 'layer-239', 'layer-24', 'layer-240', 'layer-241', 'layer-25', 'layer-26', 'layer-27', 'layer-28', 'layer-29', 'layer-3', 'layer-30', 'layer-31', 'layer-32', 'layer-33', 'layer-34', 'layer-35', 'layer-36', 'layer-37', 'layer-38', 'layer-39', 'layer-4', 'layer-40', 'layer-41', 'layer-42', 'layer-43', 'layer-44', 'layer-45', 'layer-46', 'layer-47', 'layer-48', 'layer-49', 'layer-5', 'layer-50', 'layer-51', 'layer-52', 'layer-53', 'layer-54', 'layer-55', 'layer-56', 'layer-57', 'layer-58', 'layer-59', 'layer-6', 'layer-60', 'layer-61', 'layer-62', 'layer-63', 'layer-64', 'layer-65', 'layer-66', 'layer-67', 'layer-68', 'layer-69', 'layer-7', 'layer-70', 'layer-71', 'layer-72', 'layer-73', 'layer-74', 'layer-75', 'layer-76', 'layer-77', 'layer-78', 'layer-79', 'layer-8', 'layer-80', 'layer-81', 'layer-82', 'layer-83', 'layer-84', 'layer-85', 'layer-86', 'layer-87', 'layer-88', 'layer-89', 'layer-9', 'layer-90', 'layer-91', 'layer-92', 'layer-93', 'layer-94', 'layer-95', 'layer-96', 'layer-97', 'layer-98', 'layer-99', 'layer_with_weights-0', 'layer_with_weights-1', 'layer_with_weights-10', 'layer_with_weights-100', 'layer_with_weights-101', 'layer_with_weights-102', 'layer_with_weights-103', 'layer_with_weights-104', 'layer_with_weights-105', 'layer_with_weights-106', 'layer_with_weights-107', 'layer_with_weights-108', 'layer_with_weights-109', 'layer_with_weights-11', 'layer_with_weights-110', 'layer_with_weights-111', 'layer_with_weights-112', 'layer_with_weights-113', 'layer_with_weights-114', 'layer_with_weights-115', 'layer_with_weights-116', 'layer_with_weights-117', 'layer_with_weights-118', 'layer_with_weights-119', 'layer_with_weights-12', 'layer_with_weights-120', 'layer_with_weights-121', 'layer_with_weights-122', 'layer_with_weights-123', 'layer_with_weights-124', 'layer_with_weights-125', 'layer_with_weights-126', 'layer_with_weights-127', 'layer_with_weights-128', 'layer_with_weights-129', 'layer_with_weights-13', 'layer_with_weights-130', 'layer_with_weights-131', 'layer_with_weights-132', 'layer_with_weights-14', 'layer_with_weights-15', 'layer_with_weights-16', 'layer_with_weights-17', 'layer_with_weights-18', 'layer_with_weights-19', 'layer_with_weights-2', 'layer_with_weights-20', 'layer_with_weights-21', 'layer_with_weights-22', 'layer_with_weights-23', 'layer_with_weights-24', 'layer_with_weights-25', 'layer_with_weights-26', 'layer_with_weights-27', 'layer_with_weights-28', 'layer_with_weights-29', 'layer_with_weights-3', 'layer_with_weights-30', 'layer_with_weights-31', 'layer_with_weights-32', 'layer_with_weights-33', 'layer_with_weights-34', 'layer_with_weights-35', 'layer_with_weights-36', 'layer_with_weights-37', 'layer_with_weights-38', 'layer_with_weights-39', 'layer_with_weights-4', 'layer_with_weights-40', 'layer_with_weights-41', 'layer_with_weights-42', 'layer_with_weights-43', 'layer_with_weights-44', 'layer_with_weights-45', 'layer_with_weights-46', 'layer_with_weights-47', 'layer_with_weights-48', 'layer_with_weights-49', 'layer_with_weights-5', 'layer_with_weights-50', 'layer_with_weights-51', 'layer_with_weights-52', 'layer_with_weights-53', 'layer_with_weights-54', 'layer_with_weights-55', 'layer_with_weights-56', 'layer_with_weights-57', 'layer_with_weights-58', 'layer_with_weights-59', 'layer_with_weights-6', 'layer_with_weights-60', 'layer_with_weights-61', 'layer_with_weights-62', 'layer_with_weights-63', 'layer_with_weights-64', 'layer_with_weights-65', 'layer_with_weights-66', 'layer_with_weights-67', 'layer_with_weights-68', 'layer_with_weights-69', 'layer_with_weights-7', 'layer_with_weights-70', 'layer_with_weights-71', 'layer_with_weights-72', 'layer_with_weights-73', 'layer_with_weights-74', 'layer_with_weights-75', 'layer_with_weights-76', 'layer_with_weights-77', 'layer_with_weights-78', 'layer_with_weights-79', 'layer_with_weights-8', 'layer_with_weights-80', 'layer_with_weights-81', 'layer_with_weights-82', 'layer_with_weights-83', 'layer_with_weights-84', 'layer_with_weights-85', 'layer_with_weights-86', 'layer_with_weights-87', 'layer_with_weights-88', 'layer_with_weights-89', 'layer_with_weights-9', 'layer_with_weights-90', 'layer_with_weights-91', 'layer_with_weights-92', 'layer_with_weights-93', 'layer_with_weights-94', 'layer_with_weights-95', 'layer_with_weights-96', 'layer_with_weights-97', 'layer_with_weights-98', 'layer_with_weights-99', 'optimizer', 'regularization_losses', 'signatures', 'tensorflow_git_version', 'tensorflow_version', 'trainable_variables', 'variables']\n"
     ]
    }
   ],
   "source": [
    "# Print information about the loaded SavedModel\n",
    "print(\"Loaded model signatures:\", effb0.signatures)\n",
    "print(\"Loaded model functions:\", dir(effb0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dadeb9ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_UserObject' object has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Assuming you have 'eff' and 'res' models defined somewhere above\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m eff_out \u001b[38;5;241m=\u001b[39m \u001b[43meffb0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39moutput\n\u001b[1;32m     10\u001b[0m eff_out \u001b[38;5;241m=\u001b[39m GlobalAveragePooling2D()(eff_out)\n\u001b[1;32m     12\u001b[0m res_out \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39moutput\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_UserObject' object has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Concatenate, Dense, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Your code for creating 'eff' and 'res' models\n",
    "\n",
    "num_classes = 6 \n",
    "\n",
    "# Assuming you have 'eff' and 'res' models defined somewhere above\n",
    "eff_out = eff.layers[-2].output\n",
    "eff_out = GlobalAveragePooling2D()(eff_out)\n",
    "\n",
    "res_out = res.layers[-2].output\n",
    "res_out = GlobalAveragePooling2D()(res_out)\n",
    "res_out = Reshape((1, 1, -1))(res_out)  # Reshape to (None, 1, 1, 2048)\n",
    "\n",
    "# Concatenate the processed outputs\n",
    "concatenated = Concatenate()([eff_out, res_out])\n",
    "\n",
    "# Create the final output layer\n",
    "output = Dense(num_classes, activation='softmax')(concatenated)\n",
    "\n",
    "# Create the ensemble model\n",
    "ensemble = Model(inputs=[eff.input, res.input], outputs=output)\n",
    "\n",
    "ensemble.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Assuming 'training_ds_resized' and 'testing_ds_resized' are your training and testing datasets\n",
    "ensemble.fit(training_ds_resized, validation_data=testing_ds_resized, batch_size=32, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72738aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
